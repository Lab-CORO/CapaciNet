# CapaciNet â€“ 3Dâ€‘Uâ€‘Net for Robot Reachability Maps

> **Branch:** `vae_test/unet_3d`

CapaciNet provides a complete pipeline for generating robot **R**eachability **M**aps (RMs), formatting them as voxel grids, and training a 3â€‘Dâ€‘Uâ€‘Net to predict reachability in unseen environments. The code is written for **ROSÂ 2 Humble** and **PythonÂ 3.10**. A CUDAâ€‘enabled GPU is strongly recommended for training.

---

## ğŸ“¦ Project layout

```
CapaciNet/
 â””â”€ unet_3d/
     â”œâ”€ launch/                  # ROSÂ 2 launch files
     â”‚    â”œâ”€ create_reachability_map.launch.py
     â”‚    â””â”€ generate_data.launch.py
     â”œâ”€ scripts/
     â”‚    â”œâ”€ format_data.py      # HDF5 â†’ Numpy/PNG converter
     â”‚    â””â”€ convert_to_unet.py  # Voxel grid â†’ 3â€‘Dâ€‘Uâ€‘Net dataset
     â”œâ”€ config/
     â”‚    â””â”€ train_reach.yaml    # Training hyperâ€‘parameters
     â””â”€ data/
          â”œâ”€ train/              # Raw + label volumes for training
          â””â”€ val/                # Raw + label volumes for validation
```

---

## ğŸš€ Quick start

### 1Â Â Generate the reachability map

```bash
ros2 launch unet_3d create_reachability_map.launch.py
```

This step spawns your robot in a headâ€‘less Gazebo instance and saves a coloured `.ply` RM in `~/.ros/`. Adjust the robot URDF or TCP frame as needed.

### 2Â Â Create the raw dataset

```bash
ros2 launch unet_3d generate_data.launch.py output:=${PWD}/unet_3d/data/raw
```

Each RM voxel is exported as a 3â€‘D Numpy array together with a binary reachability label.

### 3Â Â Reâ€‘format the data

```bash
python unet_3d/scripts/format_data.py --input data/raw --output data/formatted
```

This converts the Numpy blobs to `*.h5` volumes and stores metaâ€‘data such as voxel resolution, grid origin, and RM size as HDF5 attributes.

### 4Â Â Convert to the 3â€‘Dâ€‘Uâ€‘Net layout

```bash
python unet_3d/scripts/convert_to_unet.py --src data/formatted --dst data
```

The script produces the folder hierarchy expected by **pytorchâ€‘3dunet**.

### 5Â Â Split into training and validation sets

```bash
python - <<'PY'
from pathlib import Path, shutil
from sklearn.model_selection import train_test_split
files = sorted(Path('unet_3d/data/raw').glob('*.h5'))
train, val = train_test_split(files, test_size=0.2, random_state=42)
for f in train: (Path('unet_3d/data/train')/f.name).write_bytes(f.read_bytes())
for f in val:   (Path('unet_3d/data/val')/f.name).write_bytes(f.read_bytes())
PY
```

Feel free to use a different split ratio.

### 6Â Â *(Optional)* Pad the volumes

If your data dimensions are **not** divisible by the networkâ€™s stride (e.g. 16), pad them:

```bash
python unet_3d/scripts/format_data.py --pad 8
```

### 7Â Â Launch training

```bash
train3dunet --config unet_3d/config/train_reach.yaml
```

Monitor progress with **TensorBoard**:

```bash
tensorboard --logdir runs
```

---

## âš™ï¸Â Environment

```bash
# Example using Miniconda
conda create -n capacinet python=3.10
conda activate capacinet
pip install -r requirements.txt  # See root folder

#Â ROSÂ 2 Humble (UbuntuÂ 22.04)
source /opt/ros/humble/setup.bash
colcon build --packages-select unet_3d
```

Key dependencies:

* ROSÂ 2 `sensor_msgs`, `open3d_ros2`
* `PyTorchÂ >=2.0` + CUDAÂ 11.8
* `pytorchâ€‘3dunet`
* `open3d`, `h5py`, `scikitâ€‘learn`

Docker images are provided in `docker/` for reproducibility.

---

## ğŸ“ŠÂ Results & checkpoints

Preâ€‘trained weights and sample RMs are available on the [release page](https://github.com/Lab-CORO/CapaciNet/releases). To evaluate on your own reachability map:

```bash
python unet_3d/scripts/infer.py --weights checkpoints/best_model.pth --input my_map.h5
```

---

## ğŸ¤Â Contributing

Issues and PRs are welcome! Please follow the [Conventional Commits](https://www.conventionalcommits.org) style and run `preâ€‘commit` before submitting.

---

## ğŸ“„Â License

Distributed under the **MIT License**. See `LICENSE` for details.

---

## ğŸ“§Â Contact

For questions, open an [issue](https://github.com/Lab-CORO/CapaciNet/issues) or reach us at **coroâ€‘[dev@etsmtl.ca](mailto:dev@etsmtl.ca)**.

---

*Happy training!*
